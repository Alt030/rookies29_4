import requests
from bs4 import BeautifulSoup
import mysql.connector
from mysql.connector import Error
from dotenv import load_dotenv
import os

# ğŸ”¹ .env íŒŒì¼ ë¡œë“œ (DB ì ‘ì† ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°)
load_dotenv()


# ============================================
# ğŸ”¹ ì±„ìš©ê³µê³  í¬ë¡¤ë§ í•¨ìˆ˜
# ============================================
def crawl_jobs(max_pages=20):
    # í¬ë¡¤ë§ ëŒ€ìƒ URL
    url = "https://jasoseol.com/search?dutyGroupIds=166%2C175%2C176%2C177%2C178&excludeClosed=true"
    jobs = []  # í¬ë¡¤ë§í•œ ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸

    # 1~20í˜ì´ì§€ê¹Œì§€ ë°˜ë³µ í¬ë¡¤ë§
    for page in range(1, max_pages + 1):
        params = {"page": page}  # GET íŒŒë¼ë¯¸í„° ì„¤ì •
        res = requests.get(url, params=params)
        res.raise_for_status()   # ìš”ì²­ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë°œìƒ

        soup = BeautifulSoup(res.text, "html.parser")

        # ì±„ìš©ê³µê³  ëª©ë¡ì—ì„œ <a> íƒœê·¸ë§Œ ì„ íƒ
        items = soup.select("main a")

        for item in items:
            href = item.get("href")  # ìƒì„¸ í˜ì´ì§€ URL

            # íšŒì‚¬ëª… ì¶”ì¶œ
            company_tag = item.select_one("h5")
            company = company_tag.get_text(strip=True) if company_tag else "ì •ë³´ì—†ìŒ"

            # ì±„ìš© ì œëª© ì¶”ì¶œ
            title_tag = item.select_one("h4")
            title = title_tag.get_text(strip=True) if title_tag else "ì •ë³´ì—†ìŒ"

            # ì±„ìš© ê¸°ê°„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            period_tag = item.select_one("div:nth-of-type(2) > div:nth-of-type(4) > div > div")
            period_text = period_tag.get_text(strip=True) if period_tag else "ì •ë³´ì—†ìŒ"

            # "ì‹œì‘ì¼~ì¢…ë£Œì¼" í˜•íƒœì¼ ë•Œ ë¶„ë¦¬
            if "~" in period_text:
                start_date, end_date = [x.strip() for x in period_text.split("~", 1)]
            else:
                start_date = period_text
                end_date = "ì •ë³´ì—†ìŒ"

            # ìƒì„¸ í˜ì´ì§€ ë§í¬ ìƒì„±
            detail_url = "https://jasoseol.com" + href if href else "ì •ë³´ì—†ìŒ"

            # ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
            jobs.append({
                "company": company,
                "title": title,
                "start_date": start_date,
                "end_date": end_date,
                "detail": detail_url
            })

    return jobs


# ============================================
# ğŸ”¹ í¬ë¡¤ë§ ê²°ê³¼ txt íŒŒì¼ ì €ì¥ + ì¶œë ¥ í•¨ìˆ˜
# ============================================
def save_and_print(jobs, filename="pj01_test.txt"):
    with open(filename, "w", encoding="utf-8") as f:
        for job in jobs:
            # í•œ ì±„ìš©ê³µê³  ì¶œë ¥ í¬ë§·
            line = (
                f"íšŒì‚¬ëª…: {job['company']}\n"
                f"ì œëª©: {job['title']}\n"
                f"ì±„ìš©ì‹œì‘ì¼: {job['start_date']}\n"
                f"ì±„ìš©ë§ˆê°ì¼: {job['end_date']}\n"
                f"ë§í¬: {job['detail']}\n"
                "--------------------------\n"
            )
            f.write(line)  # íŒŒì¼ ì €ì¥
            print(line)    # í™”ë©´ ì¶œë ¥


# ============================================
# ğŸ”¹ MySQL DB ì €ì¥ í•¨ìˆ˜
# ============================================
def save_to_mysql(jobs):
    try:
        conn = mysql.connector.connect(
            host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASSWORD"),
            database=os.getenv("DB_NAME")
        )
        cursor = conn.cursor()

        # ğŸ”¹ DB ì¤‘ë³µ ì²´í¬ìš© SQL
        check_sql = "SELECT COUNT(*) FROM job WHERE detail = %s"

        # ğŸ”¹ ì‹ ê·œ ë°ì´í„° ì €ì¥ SQL
        insert_sql = """
        INSERT INTO job (company_name, title, start_time, end_time, detail)
        VALUES (%s, %s, %s, %s, %s)
        """

        inserted_count = 0  # ì‹¤ì œ ì €ì¥ëœ ê°œìˆ˜ ê³„ì‚°

        for job in jobs:
            # ğŸ”¸ detail ê¸°ì¤€ ì¤‘ë³µ ì²´í¬
            cursor.execute(check_sql, (job["detail"],))
            result = cursor.fetchone()

            if result[0] > 0:
                print(f"ì¤‘ë³µ ë°ì´í„° ìŠ¤í‚µë¨: {job['detail']}")
                continue  # ì¤‘ë³µ â†’ ì €ì¥ ì•ˆí•¨

            # ğŸ”¸ ì¤‘ë³µ ì•„ë‹ˆë©´ INSERT
            cursor.execute(insert_sql, (
                job["company"],
                job["title"],
                job["start_date"],
                job["end_date"],
                job["detail"]
            ))

            inserted_count += 1

        conn.commit()
        print(f"DB ì €ì¥ ì™„ë£Œ: {inserted_count}ê±´ ì €ì¥ / {len(jobs)}ê±´ ì¤‘ë³µ ì œì™¸ë¨")

    except Error as e:
        print("MySQL ì˜¤ë¥˜:", e)

    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()



# ============================================
# ğŸ”¹ ë©”ì¸ ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    # 1~20í˜ì´ì§€ í¬ë¡¤ë§
    job_list = crawl_jobs(max_pages=20)

    if job_list:
        save_and_print(job_list)   # txt ì €ì¥ + ì¶œë ¥
        save_to_mysql(job_list)    # DB ì €ì¥

        print(f"ì±„ìš©ê³µê³  {len(job_list)}ê±´ í¬ë¡¤ë§ ì™„ë£Œ / pj01_test.txt ì €ì¥ ì™„ë£Œ")
    else:
        print("í¬ë¡¤ë§ëœ ì±„ìš©ê³µê³ ê°€ ì—†ìŒ")
